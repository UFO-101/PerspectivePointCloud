{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Util function for loading point clouds|\n",
    "import numpy as np\n",
    "\n",
    "# Data structures and functions for rendering\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVOrthographicCameras, \n",
    "    FoVPerspectiveCameras,\n",
    "    PointsRasterizationSettings,\n",
    "    RasterizationSettings,\n",
    "    PointsRenderer,\n",
    "    PulsarPointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    AlphaCompositor,\n",
    "    NormWeightedCompositor)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "from torchvision.models.efficientnet_v2_m import EfficientNet, EfficientNet_V2_M_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNet(weights=EfficientNet_V2_M_Weights.IMAGENET1K_V1)\n",
    "transform_img = EfficientNet_V2_M_Weights.IMAGENET1K_V1.transforms\n",
    "\n",
    "num_points = 10\n",
    "size = 10\n",
    "verts = (torch.rand(1, num_points, 3).to(device) * size) - (size/2)\n",
    "rgb = torch.rand(1, num_points, 3).to(device)\n",
    "point_cloud = Pointclouds(points=verts, features=rgb)\n",
    "\n",
    "R, T = look_at_view_transform(dist=15, elev=10, azim=0)\n",
    "# cameras = FoVOrthographicCameras(device=device, R=R, T=T, znear=0.01)\n",
    "cameras = FoVPerspectiveCameras(device=device, R=R, T=T, znear=0.01, fov=60)\n",
    "\n",
    "raster_settings = PointsRasterizationSettings(image_size=1024, radius = 0.03, points_per_pixel = 1)\n",
    "\n",
    "# Create a points renderer by compositing points using an alpha compositor (nearer points\n",
    "# are weighted more heavily). See [1] for an explanation.\n",
    "rasterizer = PointsRasterizer(cameras=cameras, raster_settings=raster_settings)\n",
    "        \n",
    "renderer = PointsRenderer(\n",
    "    rasterizer=rasterizer,\n",
    "    compositor=AlphaCompositor()\n",
    ")\n",
    "\n",
    "images = renderer(point_cloud)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(images[0, ..., :3].cpu().numpy())\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = PulsarPointsRenderer(\n",
    "    rasterizer=PointsRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
    "    n_channels=4\n",
    ").to(device)\n",
    "\n",
    "images = renderer(point_cloud, gamma=(1e-4,),\n",
    "                  bg_col=torch.tensor([0.0, 1.0, 0.0, 1.0], dtype=torch.float32, device=device))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(images[0, ..., :3].cpu().numpy())\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
